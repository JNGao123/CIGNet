# CIGNet
This project provides the code and results for 'CIGNet: Category-and-Intrinsic-Geometry Guided Network for 3D Coarse-to-fine Reconstruction'.


## Datasets

We use the [ShapeNet](https://www.shapenet.org/), [Pix3D](http://pix3d.csail.mit.edu/) ,  [Statue Model Repository](https://lgg.epfl.ch/statues_dataset.php) and [BlendedMVS](https://github.com/YoYo000/BlendedMVS) datasets in our experiments, which are available below:

- ShapeNet rendering images: http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz
- ShapeNet voxelized models: http://cvgl.stanford.edu/data2/ShapeNetVox32.tgz
- Pix3D images & voxelized models: http://pix3d.csail.mit.edu/data/pix3d.zip

## Pretrained Models

The pretrained models on ShapeNet are available as follows:

- [CIGNet](https://pan.baidu.com/s/1TRjZymnOzjA-NNPT5s_IAQ) (PINï¼šffc0)

